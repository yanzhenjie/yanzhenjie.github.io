<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="keywords" content="严振杰,严振杰博客,严振杰|Android,严振杰|人工智能,严大,严大博客,yanzhenjie,AndServer,AndPermission"><meta name="description" content="他说正直刚烈嫉恶如仇且有勇有谋文武双全！"><meta name="author" content="严振杰"><title>人工智能|GPU加速PyTorch训练 | 严振杰</title><link rel="stylesheet" href="/css/style.css"><link rel="shortcut icon" href="/images/my_logo.svg"><link rel="stylesheet" href="/font/css/fontawesome.min.css"><link rel="stylesheet" href="/font/css/regular.min.css"><link rel="stylesheet" href="/font/css/solid.min.css"><link rel="stylesheet" href="/font/css/brands.min.css"><link rel="stylesheet" href="/css/custom.css"><script class="keep-theme-configurations">const KEEP=window.KEEP||{};KEEP.hexo_config={hostname:"www.yanzhenjie.com",root:"/",language:"zh-CN",path:"search.json"},KEEP.theme_config={base_info:{primary_color:"#ffa502",title:"严振杰",author:"严振杰",avatar:"/images/my_avatar.svg",logo:"/images/my_logo.svg",favicon:"/images/my_logo.svg",mode:"dark"},menu:{home:"/","投资":"/stock",categories:"/categories",tags:"/tags","公众号":{img:"/images/my_wechat.jpg"},"交个朋友":{children:[{"我的朋友们":"/links || fa-solid fa-link"},{"我的GitHub":"https://github.com/yanzhenjie || fa-brands fa-github"},{"我的Blog":"https://blog.yanzhenjie.com || fa-solid fa-blog"}]},about:"/about"},first_screen:{enable:!1,background_img:"/images/my_bg.svg",background_img_dark:"/images/my_bg.svg",description:"他说，正直刚烈嫉恶如仇，且有勇有谋文武双全！",hitokoto:!1},social_contact:{enable:!1,links:{github:"https://github.com/yanzhenjie",weixin:"img | /images/my_wechat.jpg",qq:null,weibo:null,zhihu:null,twitter:null,x:null,facebook:null,email:null}},scroll:{progress_bar:!0,percent:!1,hide_header:!1},home:{announcement:null,category:!0,tag:!1,post_datetime:"created",post_datetime_format:"YYYY-MM-DD HH:mm"},post:{author_badge:{enable:!1,level_badge:!0,custom_badge:["One","Two","Three"]},word_count:{wordcount:!0,min2read:!0},datetime_format:"YYYY-MM-DD HH:mm",copyright_info:{custom_license:"CC 4.0 BY-SA",custom_link:"https://creativecommons.org/licenses/by-sa/4.0/"},share:!1,reward:{enable:!0,img_link:"/images/my_reward.jpg",text:"请作者来杯Caffee",icon:"fa-solid fa-mug-hot",trigger:"hover"}},code_block:{tools:{enable:!0,style:"default"},highlight_theme:"obsidian"},toc:{enable:!0,number:!1,expand_all:!0,init_open:!0,layout:"right"},website_count:{busuanzi_count:{enable:!0,site_uv:!1,site_pv:!1,page_pv:!0}},local_search:{enable:!0,preload:!0},comment:{enable:!0,use:"valine",valine:{appid:"uUJ58UHR6Q7ezE7QwInNe5UP-gzGzoHsz",appkey:"9Hs2JzFrVSVE2JdVFid4EJBK",server_urls:null,placeholder:"这位胖友，说点什么吧"},gitalk:{github_id:null,github_admins:null,repository:null,client_id:null,client_secret:null,proxy:null},twikoo:{env_id:null,region:null,version:"1.6.39"},waline:{server_url:null,reaction:!1,version:"3.3.2"},giscus:{repo:null,repo_id:null,category:"Announcements",category_id:null,reactions_enabled:!1},artalk:{server:null},disqus:{shortname:null}},rss:{enable:!0},lazyload:{enable:!1},cdn:{enable:!1,provider:"cdnjs"},pjax:{enable:!1},footer:{since:2019,word_count:!1,site_deploy:{enable:!1,provider:"github",url:null},record:{enable:!0,list:[{code:"浙ICP备16016006号",link:"http://beian.miit.gov.cn/"},{code:"浙公网安备 33010402003470号",link:"http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33010402003470"}]}},inject:{enable:!0,css:[null,"/css/custom.css"],js:[null,"/js/custom.js"]},root:"",source_data:{links:[{title:"朋友们"},{name:"秋百万",link:"https://github.com/liaohuqiu",description:"廖祜秋，亦师亦友的前辈，对我影响颇深~",avatar:"https://avatars.githubusercontent.com/u/4088573"},{name:"玩Android",link:"https://www.wanandroid.com/",description:"鸿洋维护的技术服务站点，强烈推荐~",avatar:"/images/links/wanandroid.svg"},{name:"LongLuo’s Life Notes",link:"https://www.longluo.me",description:"一个好奇心很强的程序员~",avatar:"/images/links/longluo.svg"}]},version:"4.2.5"},KEEP.language_ago={second:"%s 秒前",minute:"%s 分钟前",hour:"%s 小时前",day:"%s 天前",week:"%s 周前",month:"%s 个月前",year:"%s 年前"},KEEP.language_code_block={copy:"复制代码",copied:"已复制",fold:"折叠代码块",folded:"已折叠"},KEEP.language_copy_copyright={copy:"复制版权信息",copied:"已复制",title:"原文标题",author:"原文作者",link:"原文链接"}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="严振杰" type="application/atom+xml"></head><body><div class="progress-bar-container"><span class="scroll-progress-bar"></span></div><main class="page-container border-box"><div class="page-main-content border-box"><div class="page-main-content-top"><header class="header-wrapper"><div class="border-box header-content"><div class="left flex-start border-box"><a class="logo-image border-box" href="/"><img src="/images/my_logo.svg"> </a><a class="site-name border-box" href="/">严振杰</a></div><div class="right border-box"><div class="pc border-box"><ul class="menu-list border-box"><li class="menu-item flex-start border-box"><a class="menu-text-color border-box" href="/">首页</a></li><li class="menu-item flex-start border-box"><a class="menu-text-color border-box" href="/stock">投资</a></li><li class="menu-item flex-start border-box"><a class="menu-text-color border-box" href="/categories">分类</a></li><li class="menu-item flex-start border-box"><a class="menu-text-color border-box" href="/tags">标签</a></li><li class="menu-item flex-start border-box has-sub-menu"><a class="menu-text-color border-box" href="javascript:void(0);">公众号 <i class="menu-text-color collapse-icon fa-solid fa-angle-down"></i></a><div class="sub-menu-list sub-menu-img-wrapper border-box"><img class="sub-menu-img" data-src="/images/my_wechat.jpg" src="/images/my_wechat.jpg"></div></li><li class="menu-item flex-start border-box has-sub-menu"><a class="menu-text-color border-box" href="javascript:void(0);">交个朋友 <i class="menu-text-color collapse-icon fa-solid fa-angle-down"></i></a><ul class="sub-menu-list border-box"><li class="sub-menu-item border-box"><a class="menu-text-color border-box flex-start" href="/links"><i class="menu-text-color sub-menu-icon fa-solid fa-link"></i> 我的朋友们</a></li><li class="sub-menu-item border-box"><a class="menu-text-color border-box flex-start" target="_blank" rel="noopener" href="https://github.com/yanzhenjie"><i class="menu-text-color sub-menu-icon fa-brands fa-github"></i> 我的GitHub</a></li><li class="sub-menu-item border-box"><a class="menu-text-color border-box flex-start" target="_blank" rel="noopener" href="https://blog.yanzhenjie.com"><i class="menu-text-color sub-menu-icon fa-solid fa-blog"></i> 我的Blog</a></li></ul></li><li class="menu-item flex-start border-box"><a class="menu-text-color border-box" href="/about">关于</a></li><li class="menu-item search search-popup-trigger"><i class="menu-text-color fas search fa-search"></i></li></ul></div><div class="mobile border-box flex-start"><div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div><div class="icon-item menu-bar"><div class="menu-bar-middle"></div></div></div></div></div><div class="header-drawer"><ul class="drawer-menu-list border-box"><li class="drawer-menu-item border-box not-sub-menu"><label class="drawer-menu-label border-box"><a class="drawer-menu-text-color left-side flex-start border-box" href="/">首页</a></label></li><li class="drawer-menu-item border-box not-sub-menu"><label class="drawer-menu-label border-box"><a class="drawer-menu-text-color left-side flex-start border-box" href="/stock">投资</a></label></li><li class="drawer-menu-item border-box not-sub-menu"><label class="drawer-menu-label border-box"><a class="drawer-menu-text-color left-side flex-start border-box" href="/categories">分类</a></label></li><li class="drawer-menu-item border-box not-sub-menu"><label class="drawer-menu-label border-box"><a class="drawer-menu-text-color left-side flex-start border-box" href="/tags">标签</a></label></li><li class="drawer-menu-item border-box has-sub-menu"><label class="drawer-menu-label border-box"><a class="drawer-menu-text-color left-side flex-start border-box" href="javascript:void(0);">公众号</a></label><div class="drawer-sub-menu-list drawer-sub-menu-img-wrapper border-box"><img class="drawer-sub-menu-img" data-src="/images/my_wechat.jpg" src="/images/my_wechat.jpg"></div></li><li class="drawer-menu-item border-box has-sub-menu"><label class="drawer-menu-label border-box"><a class="drawer-menu-text-color left-side flex-start border-box" href="javascript:void(0);">交个朋友 </a><i class="right-side collapse-icon fa-solid fa-angle-left"></i></label><ul class="drawer-sub-menu-list border-box"><li class="sub-menu-item border-box"><a class="drawer-menu-text-color border-box flex-start" href="/links"><span class="sub-menu-icon-wrap border-box flex-center"><i class="drawer-menu-text-color sub-menu-icon fa-solid fa-link"></i> </span>我的朋友们</a></li><li class="sub-menu-item border-box"><a class="drawer-menu-text-color border-box flex-start" target="_blank" rel="noopener" href="https://github.com/yanzhenjie"><span class="sub-menu-icon-wrap border-box flex-center"><i class="drawer-menu-text-color sub-menu-icon fa-brands fa-github"></i> </span>我的GitHub</a></li><li class="sub-menu-item border-box"><a class="drawer-menu-text-color border-box flex-start" target="_blank" rel="noopener" href="https://blog.yanzhenjie.com"><span class="sub-menu-icon-wrap border-box flex-center"><i class="drawer-menu-text-color sub-menu-icon fa-solid fa-blog"></i> </span>我的Blog</a></li></ul></li><li class="drawer-menu-item border-box not-sub-menu"><label class="drawer-menu-label border-box"><a class="drawer-menu-text-color left-side flex-start border-box" href="/about">关于</a></label></li></ul></div><div class="window-mask"></div></header></div><div class="page-main-content-middle border-box"><div class="main-content border-box"><div class="fade-in-down-animation"><div class="post-page-container border-box"><div class="post-content-container border-box"><div class="post-content-bottom border-box"><div class="post-title">人工智能|GPU加速PyTorch训练</div><div class="post-header border-box"><div class="avatar-box border-box"><img src="/images/my_avatar.svg"></div><div class="info-box"><div class="author border-box"><span class="name">严振杰</span></div><div class="meta-info border-box"><div class="post-meta-info-container border-box post"><div class="post-meta-info border-box"><span class="meta-info-item post-create-date"><i class="icon fa-solid fa-calendar-plus"></i>&nbsp; <span class="datetime">2024-03-13 21:20</span> </span><span class="meta-info-item post-update-date"><i class="icon fa-solid fa-file-pen"></i>&nbsp; <span class="datetime" data-updated="Fri Sep 19 2025 00:05:52 GMT+0000">2025-09-19 00:05</span> </span><span class="meta-info-item post-category border-box"><i class="icon fas fa-folder"></i>&nbsp;<ul class="post-category-ul"><li class="category-item"><a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></li></ul></span><span class="post-tag meta-info-item border-box"><ul class="post-tag-ul"><li class="tag-item"><span class="tag-separator"><i class="icon fas fa-hashtag"></i></span><a href="/tags/PyTorch/">PyTorch</a></li></ul></span><span class="meta-info-item post-wordcount"><i class="icon fas fa-file-word"></i>&nbsp;<span>1.8k 字</span> </span><span class="meta-info-item post-min2read"><i class="icon fas fa-clock"></i>&nbsp;<span>7 分钟</span> </span><span class="meta-info-item post-pv"><i class="icon fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span></span></div></div></div></div></div><div class="post-content keep-markdown-body code-block-unshrink"><h2 id="1、GPU-的并行计算"><a href="#1、GPU-的并行计算" class="headerlink" title="1、GPU 的并行计算"></a>1、GPU 的并行计算</h2><p>我在<a class="link" target="_blank" rel="noopener" href="https://yanzhenjie.blog.csdn.net/article/details/136435820">人工智能|各名称与概念之介绍<i class="fas fa-external-link-alt"></i></a>一文中提到过，深度学习是目前最主流的人工智能算法，从过程来看，它包括训练（Training）和推理（Inference）两个环节。</p><p>在训练环节，通过投喂大量的数据，训练出一个复杂的神经网络模型。在推理环节，利用训练好的模型，使用大量数据推理出各种结论。</p><p>训练环节由于涉及海量的训练数据和复杂的深度神经网络结构，所以计算规模非常庞大，对芯片的算力性能要求比较高。而推理环节，对简单指定的重复计算和实时性要求很高。模型所采用的具体算法，包括矩阵相乘、全连接层、卷积层、池化层、激活层、批归一化层和梯度运算等，分解为大量并行任务，可以有效缩短任务完成的时间。</p><p>总之，我想说明的是：<strong>神经网络模型的训练需要庞大的算力</strong>。那么它和 GPU 有什么关系呢？CPU 又在做什么？</p><p><strong>理解 CPU 的角色</strong>。如果我们把处理器看成是一个餐厅的话，CPU 就像一个拥有几十名高级厨师的全能型餐厅，它什么菜系的菜都能做。但是因为菜系众多、工序复杂和厨师较少，所以需要花费大量的时间协调和配菜，上菜的速度相对比较慢。</p><p><strong>理解 GPU 的角色</strong>。如果我们把处理器看成是一个餐厅的话，GPU 就像一个拥有千万名初级厨师的单一型餐厅，它只适合做某种指定菜系的菜。但是因为菜系单一、工序简单和厨师较多，所以仅需要少量时间通知任意一个厨师做菜，上菜速度反而快。</p><center><img src="1.png"><br>（图一）</center><p>如图一所示，左侧为 CPU 角色，右侧为 GPU 角色。GPU 凭借自身强悍的并行计算能力以及内存带宽，可以很好地应对训练和推理任务，已经成为业界在深度学习领域的首选解决方案。如果对模型进行合理优化，一块 GPU 可以提供相当于几十块 CPU 的算力。</p><blockquote><p>本小节内容引用自（有大量修改，侵删）：<a class="link" target="_blank" rel="noopener" href="https://www.toutiao.com/article/7319434384707158562">https://www.toutiao.com/article/7319434384707158562<i class="fas fa-external-link-alt"></i></a></p></blockquote><h2 id="2、CUDA-和-MPS"><a href="#2、CUDA-和-MPS" class="headerlink" title="2、CUDA 和 MPS"></a>2、CUDA 和 MPS</h2><p><code>torch.cuda</code>和<code>torch.mps</code>是 PyTorch 中的 2 个不同的模块，用于加速 PyTorch 训练。开发者在安装 PyTorch 时就需要注意安装正确的版本。我们进入官网后可以看到本地部署引导，并且会默认选中是和我们电脑的版本并给出安装命令或者安装包地址。</p><p>我们可以用鼠标点击选择自己想要安装的版本（系统、包管理、语言、计算平台）：</p><center><img src="2.gif"><br>（图二）</center><p>比如本人使用的电脑为 MBP M2，可以选择稳定版 PyTorch、MacOS、Pip、Python、计算平台为 Default，出给出安装命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch torchvision torchaudio</span><br></pre></td></tr></table></figure><p>需要注意的是，MBP M 芯片系列的电脑，计算平台中 CUDA 会被画横线，不能选择，如果强行选择则不能安装。</p><ul><li>官网地址：<a class="link" target="_blank" rel="noopener" href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/<i class="fas fa-external-link-alt"></i></a></li><li>存档版本：<a class="link" target="_blank" rel="noopener" href="https://pytorch.org/get-started/previous-versions">https://pytorch.org/get-started/previous-versions<i class="fas fa-external-link-alt"></i></a></li></ul><h3 id="2-1、非-M-芯片验证-CUDA-可用性"><a href="#2-1、非-M-芯片验证-CUDA-可用性" class="headerlink" title="2.1、非 M 芯片验证 CUDA 可用性"></a>2.1、非 M 芯片验证 CUDA 可用性</h3><p>如果是非 M 系列芯片的电脑（OS X、Linux、Window），安装命令大概率是包含 cadu 的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch</span><br><span class="line"></span><br><span class="line">conda install pytorch torchvision torchaudio cudatoolkit -c pytorch</span><br></pre></td></tr></table></figure><p>此时可以直接验证 GPU 状态是否正常可用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure><p>如果正常可用，将输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">True</span><br></pre></td></tr></table></figure><p>如果不正常，将输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">False</span><br></pre></td></tr></table></figure><p><code>torch.cuda</code>的详细 API 文档：<a class="link" target="_blank" rel="noopener" href="https://pytorch.org/docs/master/cuda.html">https://pytorch.org/docs/master/cuda.html<i class="fas fa-external-link-alt"></i></a></p><h3 id="2-2、M-芯片验证-MPS-可用性"><a href="#2-2、M-芯片验证-MPS-可用性" class="headerlink" title="2.2、M 芯片验证 MPS 可用性"></a>2.2、M 芯片验证 MPS 可用性</h3><p>如果是 M 系列芯片，那么是无法安装 CUDA 的：</p><center><img src="3.png"><br>（图三）</center><p>很早之前，PyTorch 是不支持 M 芯片的。我查了下相关信息，找到 soumith 在 PyTorch 项目下讨论过对 GPU 加速的支持：<a class="link" target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/47702">https://github.com/pytorch/pytorch/issues/47702<i class="fas fa-external-link-alt"></i></a>，2020 年 10 月的回答，有兴趣的读者可以看看。</p><p>在 2022 年 5 月 18 日，PyTorch 发布博客说 PyTorch v1.12 版本支持了 Mac OS 的 GPU 加速：<a class="link" target="_blank" rel="noopener" href="https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/">https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/<i class="fas fa-external-link-alt"></i></a>。</p><p>苹果的 MPS（Metal Performance Shaders）扩展了 PyTorch 框架，可以作为 PyTorch 的后端加速 GPU 训练，它提供了在 Mac 上设置和运行操作的脚本和功能，MPS 通过针对每个 Metal GPU 系列的独特特性进行了微调的内核来优化计算性能。</p><p>如果你安装的 PyTorch 的版本是大于等于 v1.12 的，那么默认就支持加速 PyTorch 训练的。</p><p>此时可以直接验证 GPU 状态是否正常可用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.backends.mps.is_available()</span><br></pre></td></tr></table></figure><p>如果正常可用，此时将输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">True</span><br></pre></td></tr></table></figure><p>如果不正常，此时将输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">False</span><br></pre></td></tr></table></figure><p><code>torch.mps</code>的详细 API 文档：</p><ul><li><a class="link" target="_blank" rel="noopener" href="https://pytorch.org/docs/master/mps.html">https://pytorch.org/docs/master/mps.html<i class="fas fa-external-link-alt"></i></a></li><li><a class="link" target="_blank" rel="noopener" href="https://pytorch.org/docs/master/notes/mps.html">https://pytorch.org/docs/master/notes/mps.html<i class="fas fa-external-link-alt"></i></a></li></ul><h2 id="3、CPU-和-GPU-的切换"><a href="#3、CPU-和-GPU-的切换" class="headerlink" title="3、CPU 和 GPU 的切换"></a>3、CPU 和 GPU 的切换</h2><p>首先需要确定在设备上有 1 个或者多个 GPU 可用，在 2 中我们已经确认过了。现在我们需要将我们的数据转移到 GPU 可以看到的地方，是什么意思呢？我们知道 CPU 做计算靠的是 RAM，GPU 做计算靠的是 VRAM（Video Random Access Memory），VRAM 是 GPU 的专用内存。因此我们可以说把数据移动到 GPU 连接的内存，或者简称把数据移动到 GPU。</p><p>默认情况下，我们创建张量是在 CPU 设备上的（打印张量时，通过张量的属性可以看到）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.Tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(x, x.device)</span><br></pre></td></tr></table></figure><p>此时可以看到输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1., 2., 3.]) cpu</span><br></pre></td></tr></table></figure><p>以<code>torch.rand()</code>函数为例，如果我们事先知道此时 GPU 的可用状态，那么我们直接创建即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    my_device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line"><span class="keyword">elif</span> torch.backends.mps.is_available():</span><br><span class="line">    my_device = torch.device(<span class="string">&#x27;mps&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    my_device = torch.device(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Device: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(my_device))</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">2</span>, <span class="number">2</span>, device=my_device)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><p>如果 GPU 支持<code>cuda</code>，此时可以看到输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Device: cuda</span><br><span class="line">tensor([[0.0024, 0.6778],</span><br><span class="line">        [0.2441, 0.6812]], device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br></pre></td></tr></table></figure><p>如果 GPU 支持<code>mps</code>，此时可以看到输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Device: mps</span><br><span class="line">tensor([[0.5986, 0.4086],</span><br><span class="line">        [0.0624, 0.7131]], device=<span class="string">&#x27;mps:0&#x27;</span>)</span><br></pre></td></tr></table></figure><p>当然，每次写一堆<code>if else</code>会感觉比较费劲，可以用三元表达式简写它们：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">device_name = (</span><br><span class="line">    <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;mps&quot;</span></span><br><span class="line">    <span class="keyword">if</span> torch.backends.mps.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(device_name)</span><br></pre></td></tr></table></figure><p>OK，现在我们可以使用<code>.to</code>函数让张量在 CPU 和 GPU 之间进行切换了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先拿到处理器名称</span></span><br><span class="line">device_name = (</span><br><span class="line">    <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;mps&quot;</span></span><br><span class="line">    <span class="keyword">if</span> torch.backends.mps.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 声明处理器</span></span><br><span class="line">cpu_device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">gpu_device = torch.device(device_name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 声明张量</span></span><br><span class="line">x = torch.Tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到CPU</span></span><br><span class="line">x = x.to(cpu_device)</span><br><span class="line"><span class="built_in">print</span>(x, x.device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到GPU</span></span><br><span class="line">x = x.to(gpu_device)</span><br><span class="line"><span class="built_in">print</span>(x, x.device)</span><br></pre></td></tr></table></figure><p>此时可以看到输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([1., 2., 3.]) cpu</span><br><span class="line">tensor([1., 2., 3.], device=<span class="string">&#x27;mps:0&#x27;</span>) mps:0</span><br></pre></td></tr></table></figure><p>PyTorch 官网一个很老的文档，但不及本文新：<a class="link" target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html#moving-to-gpu">https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html#moving-to-gpu<i class="fas fa-external-link-alt"></i></a></p><p>有兴趣一起交流学习的，可以加我的QQ群：874450808</p><p>本文完！</p></div><div class="post-copyright-info-container border-box"><div class="copyright-info-content border-box"><div class="copyright-info-top border-box"><div class="copyright-post-title border-box text-ellipsis">人工智能|GPU加速PyTorch训练</div><a id="post_copyright_info_link" class="copyright-post-link border-box" href="/post/20240313/a6452f4cd3d9/">post/20240313/a6452f4cd3d9/</a></div><div class="copyright-info-bottom border-box"><div class="copyright-post-author bottom-item"><div class="type">作者</div><div class="content">严振杰</div></div><div class="post-time bottom-item"><div class="type">发布于</div><div class="content">2024-03-13 21:20</div></div><div class="post-license bottom-item"><div class="type">许可</div><div class="content tooltip" data-tooltip-content=""><a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">CC 4.0 BY-SA</a></div></div></div><i class="copyright-bg fa-solid fa-copyright"></i></div><div class="copy-copyright-info flex-center tooltip" data-tooltip-content="复制版权信息" data-tooltip-offset-y="-2px"><i class="fa-solid fa-copy"></i></div></div><div class="post-bottom-tags-and-share border-box"><div><ul class="post-tags-box border-box"><li class="tag-item border-box"><i class="icon fas fa-hashtag"></i>&nbsp;<a href="/tags/PyTorch/">PyTorch</a></li></ul></div><div></div></div><div class="reward-author-container border-box flex-center"><div class="reward-btn border-box flex-center tooltip tooltip-img" data-tooltip-img-url="/images/my_reward.jpg" data-tooltip-img-trigger="hover" data-tooltip-img-style="top: -6px;"><i class="fa-solid fa-mug-hot"></i>&nbsp;请作者来杯CAFFEE</div></div><div class="post-nav border-box"><div class="prev-post"><a class="prev" rel="prev" href="/post/20240406/b3b882a8973b/" title="Android Perfetto Trace性能分析"><span class="left arrow-icon flex-center"><i class="fas fa-chevron-left"></i> </span><span class="title flex-center"><span class="post-nav-title-item text-ellipsis">Android Perfetto Trace性能分析</span> <span class="post-nav-item">上一篇</span></span></a></div><div class="next-post"><a class="next" rel="next" href="/post/20240304/dc8ba6d4ee26/" title="人工智能|各名称与概念认识"><span class="title flex-center"><span class="post-nav-title-item text-ellipsis">人工智能|各名称与概念认识</span> <span class="post-nav-item">下一篇</span> </span><span class="right arrow-icon flex-center"><i class="fas fa-chevron-right"></i></span></a></div></div><div class="comments-container border-box"><div id="comments-anchor" class="comment-area-title border-box"><i class="fas fa-comments"></i>&nbsp;评论</div><div class="comment-plugin-fail border-box"><span class="fail-tip">评论插件加载失败</span> <button class="reload keep-button">点击重新加载</button></div><div class="comment-plugin-loading flex-center border-box"><i class="loading-icon fa-solid fa-spinner fa-spin"></i> <span class="load-tip">正在加载评论插件</span></div><script data-pjax>window.KeepCommentPlugin={},window.KeepCommentPlugin.hideLoading=()=>{document.querySelector(".comments-container .comment-plugin-loading").style.display="none"},window.KeepCommentPlugin.loadFailHandle=()=>{window.KeepCommentPlugin.hideLoading();const e=document.querySelector(".comments-container .comment-plugin-fail");e.style.display="flex",e.querySelector(".reload").addEventListener("click",()=>{window.location.reload()})}</script><div class="valine-container"><div id="vcomments"></div><script src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js" async onerror="window.KeepCommentPlugin.loadFailHandle()"></script><script async onerror="window.KeepCommentPlugin.loadFailHandle()">window.KeepCommentPlugin.initValine=()=>{const e={el:"#vcomments",appId:"uUJ58UHR6Q7ezE7QwInNe5UP-gzGzoHsz",appKey:"9Hs2JzFrVSVE2JdVFid4EJBK",meta:["nick","mail","link"],avatar:"wavatar",enableQQ:!0,placeholder:"这位胖友，说点什么吧",lang:"zh-CN".toLowerCase()};window?.Valine?(new Valine(e),window.KeepCommentPlugin.hideLoading()):setTimeout(()=>{window.KeepCommentPlugin.initValine()},1e3)},window.addEventListener("DOMContentLoaded",window.KeepCommentPlugin.initValine)</script></div></div></div></div><div class="pc-post-toc right-toc"><div class="post-toc-wrap border-box"><div class="post-toc border-box"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81GPU-%E7%9A%84%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97"><span class="nav-text">1、GPU 的并行计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2%E3%80%81CUDA-%E5%92%8C-MPS"><span class="nav-text">2、CUDA 和 MPS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1%E3%80%81%E9%9D%9E-M-%E8%8A%AF%E7%89%87%E9%AA%8C%E8%AF%81-CUDA-%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="nav-text">2.1、非 M 芯片验证 CUDA 可用性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2%E3%80%81M-%E8%8A%AF%E7%89%87%E9%AA%8C%E8%AF%81-MPS-%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="nav-text">2.2、M 芯片验证 MPS 可用性</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3%E3%80%81CPU-%E5%92%8C-GPU-%E7%9A%84%E5%88%87%E6%8D%A2"><span class="nav-text">3、CPU 和 GPU 的切换</span></a></li></ol></div></div></div></div></div></div></div><div class="page-main-content-bottom border-box"><footer class="footer border-box"><div class="copyright-info info-item">&copy;&nbsp;<span>2019</span>&nbsp;-&nbsp;2025 &nbsp;<a href="/">严振杰</a></div><div class="theme-info info-item">本站由&nbsp;<a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;技术驱动&nbsp;|&nbsp;基于&nbsp;<a class="keep-version" target="_blank" href="https://github.com/yanzhenjie/hexo-theme-keep">Keep</a>&nbsp;主题</div><div class="record-info info-item"><div class="record-item border-box"><a class="" target="_blank" href="http://beian.miit.gov.cn/">浙ICP备16016006号</a></div><div class="record-item border-box"><a class="" target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33010402003470">浙公网安备 33010402003470号</a></div></div></footer></div></div><div class="post-tools right-toc"><div class="post-tools-container border-box"><ul class="post-tools-list border-box"><li class="tools-item flex-center toggle-show-toc"><i class="fas fa-list"></i></li><li class="tools-item flex-center go-to-comments"><i class="fas fa-comment"></i> <span class="post-comments-count"></span></li><li class="tools-item flex-center full-screen"><i class="fa-solid fa-expand"></i></li></ul></div></div><div class="side-tools"><div class="side-tools-container border-box"><ul class="side-tools-list side-tools-show-handle border-box"><li class="tools-item tool-font-adjust-plus flex-center"><i class="fas fa-search-plus"></i></li><li class="tools-item tool-font-adjust-minus flex-center"><i class="fas fa-search-minus"></i></li><li class="tools-item rss flex-center"><a class="flex-center" href="/atom.xml" target="_blank"><i class="fas fa-rss"></i></a></li><li class="tools-item tool-scroll-to-bottom flex-center"><i class="fas fa-arrow-down"></i></li></ul><ul class="exposed-tools-list border-box"><li class="tools-item toggle-show-toc-tablet flex-center"><i class="fas fa-list"></i></li><li class="tools-item go-to-comments-tablet flex-center"><i class="fas fa-comment"></i></li><li class="tools-item tool-toggle-show flex-center"><i class="fas fa-cog fa-spin"></i></li><li class="tools-item tool-scroll-to-top flex-center show-arrow"><i class="arrow fas fa-arrow-up"></i> <span class="percent"></span></li></ul></div></div><div class="zoom-in-image-mask"><img class="zoom-in-image"></div><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-input-field-pre"><i class="fas fa-keyboard"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="close-popup-btn"><i class="fas fa-times"></i></span></div><div id="search-result"><div id="no-result"><i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div><div class="tablet-post-toc-mask"><div class="tablet-post-toc"><div class="post-toc-wrap border-box"><div class="post-toc border-box"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81GPU-%E7%9A%84%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97"><span class="nav-text">1、GPU 的并行计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2%E3%80%81CUDA-%E5%92%8C-MPS"><span class="nav-text">2、CUDA 和 MPS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1%E3%80%81%E9%9D%9E-M-%E8%8A%AF%E7%89%87%E9%AA%8C%E8%AF%81-CUDA-%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="nav-text">2.1、非 M 芯片验证 CUDA 可用性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2%E3%80%81M-%E8%8A%AF%E7%89%87%E9%AA%8C%E8%AF%81-MPS-%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="nav-text">2.2、M 芯片验证 MPS 可用性</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3%E3%80%81CPU-%E5%92%8C-GPU-%E7%9A%84%E5%88%87%E6%8D%A2"><span class="nav-text">3、CPU 和 GPU 的切换</span></a></li></ol></div></div></div></div></main><script src="/js/utils.js"></script><script src="/js/header-shrink.js"></script><script src="/js/back2top.js"></script><script src="/js/toggle-theme.js"></script><script src="/js/code-block.js"></script><script src="/js/main.js"></script><script src="/js/libs/anime.min.js"></script><script src="/js/local-search.js"></script><div class=""><script src="/js/post/post-helper.js"></script><script src="/js/post/toc.js"></script></div><script class="custom-inject-js" src="/js/custom.js" data-pjax></script></body></html>